{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L Layer Deep Neural Network From Scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMH60qu0NQxuCHu+10gywA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prd-dahal/AI_Projects/blob/master/L_Layer_Deep_Neural_Network_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUaXqC-TljZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dependencies\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBL_pwONna_q",
        "colab_type": "code",
        "outputId": "c2d6aced-d704-46d3-f9b2-487a480c6383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Main Class \n",
        "\n",
        "class NeuralNetwork:\n",
        "  #initialize the class with hyperparameters. Here L is the depth and N is the array \n",
        "  #that contains the no of node in each Depth\n",
        "  def __init__(self, alpha=0.01, num_iter = 25, verbose='False', threshold=0.0001, L=3, N=[4,2,1]):\n",
        "    self.alpha = alpha\n",
        "    self.num_iter = num_iter\n",
        "    self.verbose = verbose \n",
        "    self.threshold = threshold \n",
        "    self.L = L\n",
        "    self.N = N\n",
        "    self.nx = 0\n",
        "    self.m = 0\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "\n",
        "    #variable for forward propagation\n",
        "    self.Z = {}\n",
        "    self.A = {}\n",
        "\n",
        "    #variable for backward propagation\n",
        "    self.dZ = {}\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dA = {}\n",
        "\n",
        "  def __sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "   \n",
        "  #relu activation\n",
        "  def __relu(self,Z):\n",
        "    return np.maximum(0,Z)\n",
        "  \n",
        "  #relu derivative activation\n",
        "  def __reluDerivative(self,Z):\n",
        "       Z[Z<=0] = 0\n",
        "       Z[Z>0] = 1\n",
        "       return Z\n",
        "  #predict the value for given input x\n",
        "  def predict(self,x):\n",
        "    A = {}\n",
        "    A[0] = x\n",
        "    Z = {}\n",
        "    for i in range(1,self.L+1):\n",
        "        if(i<(self.L)):\n",
        "          Z[i] = np.dot(self.W[i], A[i-1])+ self.B[i]\n",
        "          A[i] = self.__relu(Z[i])\n",
        "        else:\n",
        "          Z[i] = np.dot(self.W[i],A[i-1])+self.B[i]\n",
        "          A[i] = self.__sigmoid(Z[i])\n",
        "    return A[self.L].mean()\n",
        "  #initialize weights   \n",
        "  def __weightInitialize(self):\n",
        "    self.N.insert(0,self.nx)\n",
        "    for i in range(1,self.L+1):\n",
        "      self.W[i] = np.random.randn(self.N[i],self.N[i-1])\n",
        "      self.B[i] = np.random.randn(self.N[i],1)\n",
        "    \n",
        "  def fit(self,X,y):\n",
        "\n",
        "    self.nx = X.shape[0]\n",
        "    self.m = X.shape[1]\n",
        "    \n",
        "    #initialize all the weights and bias\n",
        "    self.__weightInitialize()\n",
        "    self.A[0] = X\n",
        "    \n",
        "    for t in range(self.num_iter):\n",
        "      ##START OF FORWARD PROPAGATION\n",
        "      \n",
        "      for i in range(1,self.L+1):\n",
        "        if(i<(self.L)):\n",
        "          self.Z[i] = np.dot(self.W[i], self.A[i-1])+ self.B[i]\n",
        "          self.A[i] = self.__relu(self.Z[i])\n",
        "        else:\n",
        "          self.Z[i] = np.dot(self.W[i],self.A[i-1])+self.B[i]\n",
        "          self.A[i] = self.__sigmoid(self.Z[i])\n",
        "          \n",
        "      ##END OF FORWARD PROPAGATION\n",
        "      \n",
        "      ##Error Calculation\n",
        "      #ERROR CALCULATION\n",
        "      j = - (y * np.log(self.A[self.L]) + (1-y) * np.log(1-self.A[self.L])) #error calculation\n",
        "      J = j.mean()\n",
        "      if(self.verbose==True):\n",
        "        print(\"The error at this iteration {} is {}\".format(t,J))\n",
        "      \n",
        "      ##START OF BACKWARD PROPAGATION\n",
        "      self.dZ[self.L] = self.A[self.L] - y\n",
        "      self.dW[self.L] = (1/self.m) * np.dot(self.dZ[self.L],self.A[self.L].T)\n",
        "      self.dB[self.L] = (1/self.m) * np.sum(self.dZ[self.L],axis=1,keepdims=True)\n",
        "      self.dA[self.L-1] = np.dot(self.W[self.L].T, self.dZ[self.L]) \n",
        "      for i in range(self.L-1,0,-1):\n",
        "        self.dZ[i] = self.dA[i] * self.__reluDerivative(self.Z[i])\n",
        "        self.dW[i] = (1/self.m) * np.dot(self.dZ[i],self.A[i-1].T)\n",
        "        self.dB[i] = (1/self.m) * np.sum(self.dZ[i],axis=1, keepdims=True)\n",
        "        self.dA[i-1] = np.dot(self.W[i].T,self.dZ[i])\n",
        "      ##END OF BACKWARD PROPAGATION\n",
        "\n",
        "      ##WEIGHT UPDATE START\n",
        "      for i in range(1,self.L+1):\n",
        "        self.W[i] = self.W[i] - self.alpha * self.dW[i]\n",
        "        self.B[i] = self.B[i] - self.alpha * self.dB[i]\n",
        "      ## WEIGHT UPDATE ENDS     \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  X = np.array([[1,2,3],\n",
        "                [4,5,6],\n",
        "                [8,9,10],\n",
        "                [11,12,13]])\n",
        "  X = X.T\n",
        "  y = np.array([1,0,1,1])\n",
        "\n",
        "  nn = NeuralNetwork(verbose=False)\n",
        "  nn.fit(X,y)\n",
        "  print(nn.predict(np.array([1,2,3])))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7515011570492661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBuvStgwqqNB",
        "colab_type": "code",
        "outputId": "1d4f0522-8037-482f-e389-36af105c32b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for i in range(1,3):\n",
        "  print(i)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}